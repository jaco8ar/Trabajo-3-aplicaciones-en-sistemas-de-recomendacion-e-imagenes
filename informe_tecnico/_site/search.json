[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Introducción",
    "section": "",
    "text": "Juan José Correa Hurtado\n        Jacobo Ochoa Ramírez\n    \n    \n    \n        Juan David Ospina Arango\nEn el contexto actual, las empresas de transporte enfrentan desafíos crecientes relacionados con la eficiencia operativa, la seguridad vial y la satisfacción del usuario. Factores como la variabilidad en la demanda, los riesgos asociados a la conducción distractiva y la necesidad de ofrecer experiencias personalizadas exigen soluciones tecnológicas avanzadas. Este proyecto propone el desarrollo de un sistema inteligente integrado basado en técnicas de aprendizaje profundo, con el objetivo de abordar tres problemáticas clave: la predicción de la demanda de transporte mediante series de tiempo, la clasificación automática de comportamientos distractores en conductores a partir de imágenes, y la recomendación personalizada de destinos de viaje para los usuarios."
  },
  {
    "objectID": "index.html#objetivo-general",
    "href": "index.html#objetivo-general",
    "title": "Introducción",
    "section": "1.1 Objetivo General",
    "text": "1.1 Objetivo General\nDesarrollar un sistema inteligente integrado basado en aprendizaje profundo que permita predecir la demanda de transporte, clasificar comportamientos distractores en conductores a partir de imágenes y generar recomendaciones personalizadas de destinos de viaje, con el fin de optimizar la eficiencia operativa, mejorar la seguridad vial y elevar la experiencia del usuario en una empresa de transporte."
  },
  {
    "objectID": "index.html#objetivos-especificos",
    "href": "index.html#objetivos-especificos",
    "title": "Introducción",
    "section": "1.2 Objetivos especificos",
    "text": "1.2 Objetivos especificos\n\nDesarrollar un modelo de series de tiempo que utilice datos históricos para predecir la demanda de transporte en rutas específicas durante los próximos 30 días, facilitando una mejor planificación de recursos.\nEntrenar un modelo de clasificación de imágenes para identificar comportamientos distractores en los conductores, como el uso del teléfono móvil o la somnolencia, con el fin de reducir riesgos de accidentes.\nImplementar un sistema de recomendación personalizado que sugiera destinos de viaje a los usuarios, utilizando información del historial de viajes y preferencias individuales.\nDiseñar una herramienta web interactiva que integre los tres módulos desarrollados, permitiendo la visualización de predicciones, la clasificación de imágenes y la generación de recomendaciones de manera accesible para los usuarios y administradores de la empresa.\nDocumentar el proceso completo de desarrollo en un informe técnico."
  },
  {
    "objectID": "index.html#punto-3",
    "href": "index.html#punto-3",
    "title": "Introducción",
    "section": "2.1 Punto 3",
    "text": "2.1 Punto 3\n#Importar librerías necesarias\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics.pairwise import cosine_similarity\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.utils.class_weight import compute_class_weight\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error\nfrom sklearn.decomposition import TruncatedSVD\nfrom sklearn.preprocessing import MultiLabelBinarizer\n\n2.1.1 Carga de datos\n#ES NECESARIO SUBIR LOS CSV AL COLAB\ndestinations_df = pd.read_csv(\"Expanded_Destinations.csv\")\nreviews_df = pd.read_csv(\"Final_Updated_Expanded_Reviews.csv\")\nuserhistory_df = pd.read_csv(\"Final_Updated_Expanded_UserHistory.csv\")\nusers_df = pd.read_csv(\"Final_Updated_Expanded_Users.csv\")\n# Tipado uniforme\nfor df in [users_df, userhistory_df, reviews_df]:\n    df['UserID'] = df['UserID'].astype(str)\nfor df in [destinations_df, userhistory_df, reviews_df]:\n    df['DestinationID'] = df['DestinationID'].astype(str)\n\n# Combinar datasets\n\nmerged_df = pd.merge(userhistory_df, users_df, on='UserID', how='left')\n\nmerged_df = pd.merge(merged_df, destinations_df, on='DestinationID', how='left')\n\ndf = merged_df\n\ndf.info()\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 999 entries, 0 to 998\nData columns (total 16 columns):\n #   Column            Non-Null Count  Dtype  \n---  ------            --------------  -----  \n 0   HistoryID         999 non-null    int64  \n 1   UserID            999 non-null    object \n 2   DestinationID     999 non-null    object \n 3   VisitDate         999 non-null    object \n 4   ExperienceRating  999 non-null    int64  \n 5   Name_x            999 non-null    object \n 6   Email             999 non-null    object \n 7   Preferences       999 non-null    object \n 8   Gender            999 non-null    object \n 9   NumberOfAdults    999 non-null    int64  \n 10  NumberOfChildren  999 non-null    int64  \n 11  Name_y            999 non-null    object \n 12  State             999 non-null    object \n 13  Type              999 non-null    object \n 14  Popularity        999 non-null    float64\n 15  BestTimeToVisit   999 non-null    object \ndtypes: float64(1), int64(4), object(11)\nmemory usage: 125.0+ KB\n#Convertir la fecha a datetime \ndf['VisitDate'] = pd.to_datetime(df['VisitDate'])\n#Eliminar columnas irrelevantes\ndf_copia = df.drop(columns=['HistoryID','Name_x','Email'])\n#Normalizando columnas categóricas\ndf_copia['PreferencesList'] = df_copia['Preferences'].str.split(',')\ndf_copia['Type'] = df_copia['Type'].str.lower()\ndf_copia['BestTimeToVisit'] = df_copia['BestTimeToVisit'].str.lower()\ndf_copia['PopularityNormalizado'] = (df_copia['Popularity'] - df_copia['Popularity'].min()) / (df_copia['Popularity'].max() - df_copia['Popularity'].min())\ndf_copia['ExperienceRatingNormalizado'] = (df_copia['ExperienceRating'] - df_copia['ExperienceRating'].min()) / (df_copia['ExperienceRating'].max() - df_copia['ExperienceRating'].min())\ndf_copia.head()\n\n&lt;div&gt;\n\n\n\n\n\n\n\nUserID\n\n\nDestinationID\n\n\nVisitDate\n\n\nExperienceRating\n\n\nPreferences\n\n\nGender\n\n\nNumberOfAdults\n\n\nNumberOfChildren\n\n\nName_y\n\n\nState\n\n\nType\n\n\nPopularity\n\n\nBestTimeToVisit\n\n\nPreferencesList\n\n\nPopularityNormalizado\n\n\nExperienceRatingNormalizado\n\n\n\n\n\n\n0\n\n\n525\n\n\n760\n\n\n2024-01-01\n\n\n3\n\n\nCity, Historical\n\n\nFemale\n\n\n2\n\n\n2\n\n\nLeh Ladakh\n\n\nJammu and Kashmir\n\n\nadventure\n\n\n8.352180\n\n\napr-jun\n\n\n[City, Historical]\n\n\n0.424836\n\n\n0.50\n\n\n\n\n1\n\n\n184\n\n\n532\n\n\n2024-02-15\n\n\n5\n\n\nBeaches, Historical\n\n\nMale\n\n\n1\n\n\n2\n\n\nGoa Beaches\n\n\nGoa\n\n\nbeach\n\n\n8.988127\n\n\nnov-mar\n\n\n[Beaches, Historical]\n\n\n0.743557\n\n\n1.00\n\n\n\n\n2\n\n\n897\n\n\n786\n\n\n2024-03-20\n\n\n2\n\n\nCity, Historical\n\n\nFemale\n\n\n1\n\n\n2\n\n\nTaj Mahal\n\n\nUttar Pradesh\n\n\nhistorical\n\n\n8.389206\n\n\nnov-feb\n\n\n[City, Historical]\n\n\n0.443392\n\n\n0.25\n\n\n\n\n3\n\n\n470\n\n\n660\n\n\n2024-01-01\n\n\n1\n\n\nNature, Adventure\n\n\nMale\n\n\n2\n\n\n1\n\n\nLeh Ladakh\n\n\nJammu and Kashmir\n\n\nadventure\n\n\n7.923388\n\n\napr-jun\n\n\n[Nature, Adventure]\n\n\n0.209936\n\n\n0.00\n\n\n\n\n4\n\n\n989\n\n\n389\n\n\n2024-02-15\n\n\n4\n\n\nNature, Adventure\n\n\nMale\n\n\n2\n\n\n1\n\n\nKerala Backwaters\n\n\nKerala\n\n\nnature\n\n\n9.409146\n\n\nsep-mar\n\n\n[Nature, Adventure]\n\n\n0.954561\n\n\n0.75\n\n\n\n\n\n&lt;div class=\"colab-df-buttons\"&gt;\n\n&lt;button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f5309b41-e607-448b-8b18-e18f507b4227')\"\n        title=\"Convert this dataframe to an interactive table.\"\n        style=\"display:none;\"&gt;\n \nCreación de la matriz de usuarios para hacer la recomendación de destinos de viaje.\nuser_item_matrix = df_copia.pivot_table(index='UserID', columns='DestinationID', values='ExperienceRatingNormalizado', fill_value=0)\nsvd = TruncatedSVD(n_components=20, random_state=42)\nitem_embeddings = svd.fit_transform(user_item_matrix.T)\ndestination_similarity = cosine_similarity(item_embeddings)\n\n# Índices de destinos\ndestination_indices = {\n    dest: idx for idx, dest in enumerate(user_item_matrix.columns)\n}\n\n# Base para contenido\ndestination_content = df_copia[[\n    \"DestinationID\",\n    \"Name_y\",\n    \"PopularityNormalizado\",\n    \"PreferencesList\",\n    \"Type\",\n    \"BestTimeToVisit\"\n]].drop_duplicates(subset=[\"DestinationID\"])\n\n# MultiLabelBinarizer para PreferencesList (lista de preferencias de los usuarios)\nmlb = MultiLabelBinarizer()\nprefs_encoded = pd.DataFrame(\n    mlb.fit_transform(destination_content[\"PreferencesList\"]),\n    columns=[f\"Pref_{c}\" for c in mlb.classes_]\n)\nprefs_encoded.index = destination_content.index\n\n# One-hot encode Type y BestTimeToVisit\ndummies = pd.get_dummies(destination_content[[\"Type\", \"BestTimeToVisit\"]])\n\n# Concatenar\ndestination_content_encoded = pd.concat([\n    destination_content[[\"DestinationID\", \"Name_y\", \"PopularityNormalizado\"]],\n    dummies,\n    prefs_encoded\n], axis=1)\n\n# Asegurarse que todo sea float\nfor col in destination_content_encoded.columns:\n    if destination_content_encoded[col].dtype in [bool, int]:\n        destination_content_encoded[col] = destination_content_encoded[col].astype(float)\n\n\nuser_similarity = cosine_similarity(destination_content_encoded.drop(columns=[\"DestinationID\", \"Name_y\"]) )\ndestinations_names = df_copia[['DestinationID', 'Name_y']].drop_duplicates()\n\n2.1.2 Función para recomendación de los top 5 destinos con un alpha de 0.5 (uno con base en destinos similares que el usuario ya visitó collab_scores y otro con base en contenido de los destinos ya visitados content_scores) el alpha determinar que ambos parámetros tienen la misma importancia.\ndef recommend_destinations(user_id,top_n=5,alpha=0.5):\n  if user_id not in user_item_matrix.index:\n    print('Usuario no válido')\n    return 0\n  visited_destinations = user_item_matrix.columns[user_item_matrix.loc[user_id] &gt; 0]\n  collab_scores = np.zeros(len(user_item_matrix.columns))\n  content_scores = np.zeros(len(user_item_matrix.columns))\n\n  for d in visited_destinations:\n    idx = destination_indices[d]\n    collab_scores += destination_similarity[idx]\n    content_scores += user_similarity[idx]\n\n  if len(visited_destinations) &gt; 0:\n    collab_scores /= len(visited_destinations)\n    content_scores /= len(visited_destinations)\n\n  hybrid_scores = alpha * collab_scores + (1 - alpha) * content_scores\n\n  recommendations = pd.DataFrame({\n      \"DestinationID\": user_item_matrix.columns,\n      \"HybridScore\": hybrid_scores\n  })\n\n  recommendations = recommendations[~recommendations[\"DestinationID\"].isin(visited_destinations)]\n  recommendations = recommendations.merge(destinations_names, on=\"DestinationID\", how=\"left\")\n  recommendations = recommendations.groupby(\"Name_y\").agg({\"HybridScore\": \"mean\"}).reset_index()\n  recommendations = recommendations.sort_values(\"HybridScore\", ascending=False).head(top_n)\n  recommendations = recommendations.rename(columns={\"Name_y\": \"DestinationName\"})\n  return recommendations\n\n\n2.1.3 Ahora pasamos a la función para recomendación por perfil del usuario. (ideal para usuarios nuevos)\ndef recommend_by_profile(user_profile, top_n=5):\n    # One-hot de Type (puedes cambiar la lógica si quieres)\n    type_cols = [c for c in destination_content_encoded.columns if c.startswith(\"Type_\")]\n    type_vec = pd.Series(0.0, index=type_cols)\n\n    # One-hot de BestTimeToVisit (puedes ajustar la lógica)\n    time_cols = [c for c in destination_content_encoded.columns if c.startswith(\"BestTimeToVisit_\")]\n    time_vec = pd.Series(0.0, index=time_cols)\n\n    # MultiLabel de Preferences\n    pref_cols = [c for c in destination_content_encoded.columns if c.startswith(\"Pref_\")]\n    pref_vec = pd.Series(0.0, index=pref_cols)\n    for pref in user_profile[\"Preferences\"].split(\", \"):\n        col = f\"Pref_{pref.strip()}\"\n        if col in pref_vec.index:\n            pref_vec[col] = 1.0\n\n    # Popularidad media\n    popularity_mean = destination_content_encoded[\"PopularityNormalizado\"].mean()\n\n    # Concatenar\n    user_vector = pd.concat([\n        pd.Series({\"PopularityNormalizado\": popularity_mean}),\n        type_vec,\n        time_vec,\n        pref_vec\n    ]).to_frame().T\n\n    # Ordenar columnas igual que en destino\n    user_vector = user_vector[destination_content_encoded.drop(columns=[\"DestinationID\", \"Name_y\"]).columns]\n\n    # Convertir a float\n    user_vector = user_vector.astype(float)\n\n    # Similitud\n    sim = cosine_similarity(\n        destination_content_encoded.drop(columns=[\"DestinationID\", \"Name_y\"]),\n        user_vector\n    ).flatten()\n\n    recommendations = destination_content_encoded[[\"DestinationID\", \"Name_y\"]].copy()\n    recommendations[\"Similarity\"] = sim\n    recommendations = recommendations.sort_values(\"Similarity\", ascending=False).head(top_n)\n    recommendations = recommendations.rename(columns={\"Name_y\": \"DestinationName\"})\n    return recommendations\n# Recomendación híbrida basada en historial\nsample_user = df_copia[\"UserID\"].iloc[0]\nrecs_hybrid = recommend_destinations(sample_user, top_n=3, alpha=0.6)\nprint(\"\\n=== Recomendaciones híbridas ===\")\nprint(recs_hybrid)\n\n# Recomendación basada en perfil\nuser_profile = {\n    \"Preferences\": \"Nature, Adventure\",\n    \"Gender\": \"Female\",\n    \"NumberOfAdults\": 2,\n    \"NumberOfChildren\": 1\n}\nrecs_profile = recommend_by_profile(user_profile)\nprint(\"\\n=== Recomendaciones basadas en perfil ===\")\nprint(recs_profile)\n=== Recomendaciones híbridas ===\n  DestinationName  HybridScore\n1     Jaipur City     0.155404\n0     Goa Beaches     0.155140\n4       Taj Mahal     0.147836\n\n=== Recomendaciones basadas en perfil ===\n    DestinationID    DestinationName  Similarity\n860           987        Goa Beaches    0.601030\n517           468        Jaipur City    0.600173\n31            114  Kerala Backwaters    0.599672\n207           684  Kerala Backwaters    0.599624\n84            130         Leh Ladakh    0.599397\n\n\n2.1.4 Evaluación de métricas\nimport random\n\n# -------------------------------\n# Generador automático de perfiles\n# -------------------------------\ndef generate_random_profiles(n_profiles=50):\n    possible_preferences = [\n        \"Nature\", \"Adventure\", \"Culture\", \"Relaxation\", \"Beach\", \"Gastronomy\"\n    ]\n    genders = [\"Female\", \"Male\"]\n    num_adults_options = [1, 2, 3]\n    num_children_options = [0, 1, 2]\n\n    profiles = []\n    for _ in range(n_profiles):\n        selected_prefs = random.sample(possible_preferences, k=random.randint(1,2))\n        profile = {\n            \"Preferences\": \", \".join(selected_prefs),\n            \"Gender\": random.choice(genders),\n            \"NumberOfAdults\": random.choice(num_adults_options),\n            \"NumberOfChildren\": random.choice(num_children_options)\n        }\n        profiles.append(profile)\n\n    return profiles\n\n# -------------------------------\n# Evaluación contra múltiples usuarios\n# -------------------------------\ndef evaluate_profile_recommendations_against_multiple_users(user_profile, recommended_df, user_ids):\n    recommended_names = set(recommended_df[\"DestinationName\"].values)\n\n    precisions = []\n    recalls = []\n\n    for uid in user_ids:\n        actual_destinations = set(df_copia[df_copia[\"UserID\"] == uid][\"Name_y\"].unique())\n\n        if not actual_destinations:\n            continue  # Saltar usuarios sin historial\n\n        hits = recommended_names.intersection(actual_destinations)\n\n        precision = len(hits) / len(recommended_names) if recommended_names else 0\n        recall = len(hits) / len(actual_destinations) if actual_destinations else 0\n\n        precisions.append(precision)\n        recalls.append(recall)\n\n    avg_precision = sum(precisions) / len(precisions) if precisions else None\n    avg_recall = sum(recalls) / len(recalls) if recalls else None\n\n    return avg_precision, avg_recall\n\n# -------------------------------\n# Generar perfiles de prueba\n# -------------------------------\ntest_profiles = generate_random_profiles(n_profiles=50)\n\n# -------------------------------\n# Evaluar todos los perfiles\n# -------------------------------\nall_user_ids = df_copia[\"UserID\"].unique()\n\nall_precisions = []\nall_recalls = []\n\nfor idx, profile in enumerate(test_profiles):\n    # Generar recomendaciones para este perfil\n    recs_profile = recommend_by_profile(profile, top_n=5)\n\n    # Evaluar contra todos los usuarios reales\n    avg_precision, avg_recall = evaluate_profile_recommendations_against_multiple_users(\n        profile, recs_profile, all_user_ids\n    )\n\n    all_precisions.append(avg_precision)\n    all_recalls.append(avg_recall)\n\n    print(f\"Perfil {idx+1}: Precision={avg_precision:.3f}, Recall={avg_recall:.3f}\")\n\n# -------------------------------\n# Métricas promedio globales\n# -------------------------------\noverall_precision = sum(all_precisions) / len(all_precisions)\noverall_recall = sum(all_recalls) / len(all_recalls)\n\nprint(\"\\n=== Métricas de evaluación global (promedio sobre perfiles aleatorios) ===\")\nprint(f\"Precision promedio global: {overall_precision:.3f}\")\nprint(f\"Recall promedio global: {overall_recall:.3f}\")\nPerfil 1: Precision=0.282, Recall=0.802\nPerfil 2: Precision=0.278, Recall=0.591\nPerfil 3: Precision=0.278, Recall=0.591\nPerfil 4: Precision=0.278, Recall=0.591\nPerfil 5: Precision=0.282, Recall=0.802\nPerfil 6: Precision=0.278, Recall=0.591\nPerfil 7: Precision=0.282, Recall=0.802\nPerfil 8: Precision=0.282, Recall=0.802\nPerfil 9: Precision=0.282, Recall=0.802\nPerfil 10: Precision=0.278, Recall=0.591\nPerfil 11: Precision=0.278, Recall=0.591\nPerfil 12: Precision=0.278, Recall=0.591\nPerfil 13: Precision=0.278, Recall=0.591\nPerfil 14: Precision=0.278, Recall=0.591\nPerfil 15: Precision=0.278, Recall=0.591\nPerfil 16: Precision=0.278, Recall=0.591\nPerfil 17: Precision=0.278, Recall=0.591\nPerfil 18: Precision=0.282, Recall=0.802\nPerfil 19: Precision=0.278, Recall=0.591\nPerfil 20: Precision=0.278, Recall=0.591\nPerfil 21: Precision=0.278, Recall=0.591\nPerfil 22: Precision=0.282, Recall=0.802\nPerfil 23: Precision=0.278, Recall=0.591\nPerfil 24: Precision=0.278, Recall=0.591\nPerfil 25: Precision=0.278, Recall=0.591\nPerfil 26: Precision=0.278, Recall=0.591\nPerfil 27: Precision=0.278, Recall=0.591\nPerfil 28: Precision=0.282, Recall=0.802\nPerfil 29: Precision=0.278, Recall=0.591\nPerfil 30: Precision=0.278, Recall=0.591\nPerfil 31: Precision=0.278, Recall=0.591\nPerfil 32: Precision=0.282, Recall=0.802\nPerfil 33: Precision=0.278, Recall=0.591\nPerfil 34: Precision=0.278, Recall=0.591\nPerfil 35: Precision=0.278, Recall=0.591\nPerfil 36: Precision=0.278, Recall=0.591\nPerfil 37: Precision=0.282, Recall=0.802\nPerfil 38: Precision=0.278, Recall=0.591\nPerfil 39: Precision=0.278, Recall=0.591\nPerfil 40: Precision=0.278, Recall=0.591\nPerfil 41: Precision=0.282, Recall=0.802\nPerfil 42: Precision=0.282, Recall=0.802\nPerfil 43: Precision=0.278, Recall=0.591\nPerfil 44: Precision=0.278, Recall=0.591\nPerfil 45: Precision=0.282, Recall=0.802\nPerfil 46: Precision=0.278, Recall=0.591\nPerfil 47: Precision=0.278, Recall=0.591\nPerfil 48: Precision=0.278, Recall=0.591\nPerfil 49: Precision=0.282, Recall=0.802\nPerfil 50: Precision=0.282, Recall=0.802\n\n=== Métricas de evaluación global (promedio sobre perfiles aleatorios) ===\nPrecision promedio global: 0.279\nRecall promedio global: 0.655\n\n\n2.1.5 Análisis de efectividad de las recomendaciones\nEl dataset utilizado no está muy probado y los datos a veces tienden a ser muy similares los unos a los otros a tal punto que al momento de recomendar nuevos destinos a usuarios ya en la base de datos esto podía causar resultados que no tenían mucho sentido. Por otro lado, la recomendación de destinos podría personalizarse aún más buscando un alpha adecuado dependiendo del usuario y que él determine a cual criterio le daría más importancia. - Usuarios con preferencias similares reciben recomendaciones alineadas.\n\nSe puede observar un sesgo positivo hacia destinos populares, lo que puede reflejar una mayor demanda.\nLas rutas más recomendadas podrían recibir mayor tráfico si estas recomendaciones se aplican en producción. **"
  }
]