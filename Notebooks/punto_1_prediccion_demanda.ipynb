{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import zipfile\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import kagglehub\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, roc_auc_score, roc_curve, classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.metrics.pairwise import pairwise_distances\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "from prophet import Prophet"
      ],
      "metadata": {
        "id": "of1xdKqOJqIv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#ES NECESARIO SUBIR LOS CSV AL COLAB\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"amanmehra23/travel-recommendation-dataset\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)\n",
        "\n",
        "destinations_df = pd.read_csv(\"/kaggle/input/travel-recommendation-dataset/Expanded_Destinations.csv\")\n",
        "reviews_df = pd.read_csv(\"/kaggle/input/travel-recommendation-dataset/Final_Updated_Expanded_Reviews.csv\")\n",
        "userhistory_df = pd.read_csv(\"/kaggle/input/travel-recommendation-dataset/Final_Updated_Expanded_UserHistory.csv\")\n",
        "users_df = pd.read_csv(\"/kaggle/input/travel-recommendation-dataset/Final_Updated_Expanded_Users.csv\")"
      ],
      "metadata": {
        "id": "uWj5OGWHf01U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61351dcf-840e-45a2-8c4c-f5294230ddef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path to dataset files: /kaggle/input/travel-recommendation-dataset\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "display(userhistory_df.head())\n",
        "userhistory_df.info()"
      ],
      "metadata": {
        "id": "NPwt8-O5g3du"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tipado uniforme\n",
        "for df in [users_df, userhistory_df, reviews_df]:\n",
        "    df['UserID'] = df['UserID'].astype(str)\n",
        "for df in [destinations_df, userhistory_df, reviews_df]:\n",
        "    df['DestinationID'] = df['DestinationID'].astype(str)\n",
        "\n",
        "\n",
        "# Verificar valores únicos por columna\n",
        "print(\"\\nValores únicos por columna:\")\n",
        "print(userhistory_df.nunique())\n",
        "\n",
        "# Verificar valores nulos\n",
        "print(\"\\nValores nulos por columna:\")\n",
        "print(userhistory_df.isnull().sum())"
      ],
      "metadata": {
        "id": "B6uskmnSinUW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c210f2ee-a7fb-424c-daa1-1172584ed16e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Valores únicos por columna:\n",
            "HistoryID           999\n",
            "UserID              642\n",
            "DestinationID       638\n",
            "VisitDate             3\n",
            "ExperienceRating      5\n",
            "dtype: int64\n",
            "\n",
            "Valores nulos por columna:\n",
            "HistoryID           0\n",
            "UserID              0\n",
            "DestinationID       0\n",
            "VisitDate           0\n",
            "ExperienceRating    0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Combinar datasets\n",
        "\n",
        "merged_df = pd.merge(userhistory_df, users_df, on='UserID', how='left')\n",
        "\n",
        "merged_df = pd.merge(merged_df, destinations_df, on='DestinationID', how='left')\n",
        "\n",
        "#df = pd.merge(merged_df, reviews_df, on='UserID', how='left')\n",
        "df = merged_df\n",
        "df.info()"
      ],
      "metadata": {
        "id": "zhJ2tkwYjD8v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "733e4a01-01a7-4dd3-f209-a966c47cc942"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 999 entries, 0 to 998\n",
            "Data columns (total 16 columns):\n",
            " #   Column            Non-Null Count  Dtype  \n",
            "---  ------            --------------  -----  \n",
            " 0   HistoryID         999 non-null    int64  \n",
            " 1   UserID            999 non-null    object \n",
            " 2   DestinationID     999 non-null    object \n",
            " 3   VisitDate         999 non-null    object \n",
            " 4   ExperienceRating  999 non-null    int64  \n",
            " 5   Name_x            999 non-null    object \n",
            " 6   Email             999 non-null    object \n",
            " 7   Preferences       999 non-null    object \n",
            " 8   Gender            999 non-null    object \n",
            " 9   NumberOfAdults    999 non-null    int64  \n",
            " 10  NumberOfChildren  999 non-null    int64  \n",
            " 11  Name_y            999 non-null    object \n",
            " 12  State             999 non-null    object \n",
            " 13  Type              999 non-null    object \n",
            " 14  Popularity        999 non-null    float64\n",
            " 15  BestTimeToVisit   999 non-null    object \n",
            "dtypes: float64(1), int64(4), object(11)\n",
            "memory usage: 125.0+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "merged_df = pd.merge(userhistory_df, users_df, on='UserID', how='left')\n",
        "merged_df = pd.merge(merged_df,destinations_df, on='DestinationID', how='left')\n",
        "merged_df.to_csv(\"Merged_Travel_Data.csv\", index=False)\n",
        "m = pd.read_csv(\"Merged_Travel_Data.csv\")\n",
        "m.info()\n",
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZLlPRDxo1VOr",
        "outputId": "a60600a1-0c0c-4683-dcb4-7300a3085564"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 999 entries, 0 to 998\n",
            "Data columns (total 16 columns):\n",
            " #   Column            Non-Null Count  Dtype  \n",
            "---  ------            --------------  -----  \n",
            " 0   HistoryID         999 non-null    int64  \n",
            " 1   UserID            999 non-null    int64  \n",
            " 2   DestinationID     999 non-null    int64  \n",
            " 3   VisitDate         999 non-null    object \n",
            " 4   ExperienceRating  999 non-null    int64  \n",
            " 5   Name_x            999 non-null    object \n",
            " 6   Email             999 non-null    object \n",
            " 7   Preferences       999 non-null    object \n",
            " 8   Gender            999 non-null    object \n",
            " 9   NumberOfAdults    999 non-null    int64  \n",
            " 10  NumberOfChildren  999 non-null    int64  \n",
            " 11  Name_y            999 non-null    object \n",
            " 12  State             999 non-null    object \n",
            " 13  Type              999 non-null    object \n",
            " 14  Popularity        999 non-null    float64\n",
            " 15  BestTimeToVisit   999 non-null    object \n",
            "dtypes: float64(1), int64(6), object(9)\n",
            "memory usage: 125.0+ KB\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 993 entries, 0 to 992\n",
            "Data columns (total 20 columns):\n",
            " #   Column            Non-Null Count  Dtype  \n",
            "---  ------            --------------  -----  \n",
            " 0   ReviewID          993 non-null    int64  \n",
            " 1   DestinationID_x   993 non-null    object \n",
            " 2   UserID            993 non-null    object \n",
            " 3   Rating            993 non-null    int64  \n",
            " 4   ReviewText        993 non-null    object \n",
            " 5   Name_x            993 non-null    object \n",
            " 6   State             993 non-null    object \n",
            " 7   Type              993 non-null    object \n",
            " 8   Popularity        993 non-null    float64\n",
            " 9   BestTimeToVisit   993 non-null    object \n",
            " 10  HistoryID         993 non-null    int64  \n",
            " 11  DestinationID_y   993 non-null    object \n",
            " 12  VisitDate         993 non-null    object \n",
            " 13  ExperienceRating  993 non-null    int64  \n",
            " 14  Name_y            993 non-null    object \n",
            " 15  Email             993 non-null    object \n",
            " 16  Preferences       993 non-null    object \n",
            " 17  Gender            993 non-null    object \n",
            " 18  NumberOfAdults    993 non-null    int64  \n",
            " 19  NumberOfChildren  993 non-null    int64  \n",
            "dtypes: float64(1), int64(6), object(13)\n",
            "memory usage: 155.3+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Revisión de datos nulos o duplicados\n",
        "df.shape\n",
        "df.duplicated().sum()\n",
        "df.isnull().sum()\n",
        "#Eliminar columnas irrelevantes\n",
        "df_clean = df.drop(columns=['HistoryID','Name_x','Email'])\n",
        "df_clean['VisitDate'] = pd.to_datetime(df_clean['VisitDate'])"
      ],
      "metadata": {
        "id": "TbgmAx7Mkex_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(y='Name', x='Popularity', data=destinations_df.sort_values(by='Popularity', ascending=True), palette='coolwarm', hue='Name')\n",
        "plt.title('Most Popular Destinations')\n",
        "plt.xlabel('Popularity Score')\n",
        "plt.ylabel('Destination')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ITm7JYARkro1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Ver cuantoas datos hay por cada usuario\n",
        "userhistory_df.groupby('UserID').size().sort_values(ascending=False)"
      ],
      "metadata": {
        "id": "HcQUOHwRlCDo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Convertir la fecha a datetime\n",
        "df_copia = df.copy()\n",
        "df_copia['VisitDate'] = pd.to_datetime(df_copia['VisitDate'], errors='coerce')\n",
        "df_copia.info()"
      ],
      "metadata": {
        "id": "3g0UHwo4gi-7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_copia.head()"
      ],
      "metadata": {
        "id": "HR7COc84tU3r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Crear la serie de tiempo agregada: Agrupar por día y destino para contar número de viajes\n",
        "df_demand = df_copia.groupby(['VisitDate', 'Name_x']).size().reset_index(name='num_viajes')\n",
        "\n",
        "# Ordenar por fecha\n",
        "df_demand = df_demand.sort_values('VisitDate')\n",
        "\n",
        "# Ver los destinos más populares\n",
        "top_destinos = df_demand.groupby('Name_x')['num_viajes'].sum().sort_values(ascending=False)\n",
        "print(\"Destinos más visitados:\")\n",
        "print(top_destinos.head(10))\n"
      ],
      "metadata": {
        "id": "__hK-p_ukCQw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Filtar el destino con más viajes para modelar\n",
        "destino_top = top_destinos.index[0]\n",
        "\n",
        "# Filtrar los datos para ese destino\n",
        "df_top = df_demand[df_demand['Name_x'] == destino_top].copy()\n",
        "\n",
        "# Rellenar fechas faltantes con 0 viajes\n",
        "# Crear un rango continuo de fechas\n",
        "rango_fechas = pd.date_range(start=df_top['VisitDate'].min(), end=df_top['VisitDate'].max())\n",
        "\n",
        "# Reindexar para asegurar continuidad temporal\n",
        "df_top = df_top.set_index('VisitDate').reindex(rango_fechas, fill_value=0)\n",
        "df_top = df_top.rename_axis('VisitDate').reset_index()\n",
        "\n",
        "#Quitar valores nulos o vácios\n",
        "df_top=df_top[df_top['num_viajes']!=0]\n",
        "df_top.dropna(inplace=True)\n",
        "\n",
        "# Confirmar\n",
        "print(f\"\\nSerie de tiempo para destino {destino_top}\")\n",
        "display(df_top.groupby(['Name_x','VisitDate']).sum())"
      ],
      "metadata": {
        "collapsed": true,
        "id": "bakbDp94knEI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Seleccionar la ciudad más visitada (por ejemplo)\n",
        "ciudad_top = df_demand.groupby('Name_x')['num_viajes'].sum().sort_values(ascending=False).index[0]\n",
        "\n",
        "# Filtrar solo esa ciudad\n",
        "df_ciudad = df_demand[df_demand['Name_x'] == ciudad_top].copy()\n",
        "\n",
        "# Renombrar columnas como lo requiere Prophet\n",
        "df_ciudad = df_ciudad.rename(columns={'VisitDate': 'ds', 'num_viajes': 'y'})\n",
        "\n",
        "# Asegurarnos de que estén ordenadas por fecha\n",
        "df_ciudad = df_ciudad.sort_values('ds')\n",
        "\n",
        "# Mostrar datos\n",
        "print(f\"Serie de tiempo para la ciudad: {ciudad_top}\")\n",
        "display(df_ciudad)"
      ],
      "metadata": {
        "id": "cg-v3yAvoPqx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear el modelo\n",
        "modelo = Prophet(daily_seasonality=True)\n",
        "\n",
        "# Entrenar el modelo\n",
        "modelo.fit(df_ciudad)\n",
        "\n",
        "# Crear un dataframe para predicción de los próximos 30 días\n",
        "future = modelo.make_future_dataframe(periods=30)\n",
        "\n",
        "# Predecir\n",
        "forecast = modelo.predict(future)\n",
        "\n",
        "# Graficar los resultados\n",
        "modelo.plot(forecast)\n",
        "plt.title(f\"Predicción de demanda para {ciudad_top}\")\n",
        "plt.xlabel(\"Fecha\")\n",
        "plt.ylabel(\"Número de viajes\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "bX5Z4Jx-0X5l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Lista de los 5 destinos más visitados\n",
        "top_5_ciudades = df_demand.groupby('Name_x')['num_viajes'].sum().sort_values(ascending=False).head(5).index\n",
        "\n",
        "# Crear diccionario para guardar predicciones\n",
        "predicciones_por_ciudad = {}\n",
        "\n",
        "# Generar predicciones para cada ciudad\n",
        "for ciudad in top_5_ciudades:\n",
        "    df_ciudad = df_demand[df_demand['Name_x'] == ciudad][['VisitDate', 'num_viajes']].copy()\n",
        "    df_ciudad = df_ciudad.rename(columns={'VisitDate': 'ds', 'num_viajes': 'y'})\n",
        "    df_ciudad = df_ciudad.sort_values('ds')\n",
        "\n",
        "    modelo = Prophet(daily_seasonality=True)\n",
        "    modelo.fit(df_ciudad)\n",
        "\n",
        "    future = modelo.make_future_dataframe(periods=30)\n",
        "    forecast = modelo.predict(future)\n",
        "\n",
        "    predicciones_por_ciudad[ciudad] = forecast[['ds', 'yhat']].copy()\n",
        "    predicciones_por_ciudad[ciudad]['ciudad'] = ciudad"
      ],
      "metadata": {
        "collapsed": true,
        "id": "e6mpzlX9N5R-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Unir todos los forecast en un solo DataFrame\n",
        "df_predicciones_total = pd.concat(predicciones_por_ciudad.values())\n",
        "\n",
        "# Filtrar solo las fechas futuras (los 30 días siguientes)\n",
        "ultima_fecha_real = df_demand['VisitDate'].max()\n",
        "df_futuro = df_predicciones_total[df_predicciones_total['ds'] > ultima_fecha_real]\n",
        "\n",
        "# Gráfico combinado\n",
        "plt.figure(figsize=(12, 6))\n",
        "for ciudad in top_5_ciudades:\n",
        "    datos = df_futuro[df_futuro['ciudad'] == ciudad]\n",
        "    plt.plot(datos['ds'], datos['yhat'], label=ciudad)\n",
        "\n",
        "plt.title(\"Proyección de demanda para los próximos 30 días\")\n",
        "plt.xlabel(\"Fecha\")\n",
        "plt.ylabel(\"Número de viajes\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "LhrtAzY3ORSc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Métricas de evaluación (RMSE, MAE)\n",
        "print(\"Métricas de evaluación:\\n\")\n",
        "\n",
        "for ciudad in top_5_ciudades:\n",
        "    df_real = df_demand[df_demand['Name_x'] == ciudad][['VisitDate', 'num_viajes']].copy()\n",
        "    df_real = df_real.rename(columns={'VisitDate': 'ds', 'num_viajes': 'y'}).sort_values('ds')\n",
        "\n",
        "    forecast = predicciones_por_ciudad[ciudad]\n",
        "    forecast_real = forecast.merge(df_real, on='ds', how='inner')  # Solo fechas reales\n",
        "\n",
        "    rmse = np.sqrt(mean_squared_error(forecast_real['y'], forecast_real['yhat']))\n",
        "    mae = mean_absolute_error(forecast_real['y'], forecast_real['yhat'])\n",
        "\n",
        "    print(f\"{ciudad} - RMSE: {rmse:.2f} | MAE: {mae:.2f}\")"
      ],
      "metadata": {
        "id": "shylLZnMssMx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Gráficas de predicción vs demanda real\n",
        "fig, axes = plt.subplots(nrows=3, ncols=2, figsize=(15, 12))\n",
        "axes = axes.flatten()\n",
        "\n",
        "for i, ciudad in enumerate(top_5_ciudades):\n",
        "    forecast = predicciones_por_ciudad[ciudad]\n",
        "    df_real = df_demand[df_demand['Name_x'] == ciudad][['VisitDate', 'num_viajes']]\n",
        "\n",
        "    ax = axes[i]\n",
        "    ax.plot(df_real['VisitDate'], df_real['num_viajes'], 'o', label='Real')\n",
        "    ax.plot(forecast['ds'], forecast['yhat'], '-', label='Predicción')\n",
        "    ax.set_title(f\"Predicción vs Real - {ciudad}\")\n",
        "    ax.set_xlabel(\"Fecha\")\n",
        "    ax.set_ylabel(\"Número de viajes\")\n",
        "    ax.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ka22PQ_duW45"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Almacenar modelos y predicciones\n",
        "predicciones_por_ciudad = {}\n",
        "modelos_por_ciudad = {}\n",
        "\n",
        "for ciudad in top_5_ciudades:\n",
        "    df_ciudad = df_demand[df_demand['Name_x'] == ciudad][['VisitDate', 'num_viajes']].copy()\n",
        "    df_ciudad = df_ciudad.rename(columns={'VisitDate': 'ds', 'num_viajes': 'y'}).sort_values('ds')\n",
        "\n",
        "    modelo = Prophet(daily_seasonality=True)\n",
        "    modelo.fit(df_ciudad)\n",
        "\n",
        "    future = modelo.make_future_dataframe(periods=30)\n",
        "    forecast = modelo.predict(future)\n",
        "\n",
        "    predicciones_por_ciudad[ciudad] = forecast\n",
        "    modelos_por_ciudad[ciudad] = modelo\n",
        "\n",
        "# Mostrar componentes para cada ciudad\n",
        "for ciudad in top_5_ciudades:\n",
        "    print(f\"\\nComponentes del modelo para {ciudad}:\")\n",
        "    modelos_por_ciudad[ciudad].plot_components(predicciones_por_ciudad[ciudad])\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "HwhtN-gPu12q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aunque el dataset tiene un número limitado de fechas, se observan algunos indicios de variaciones diarias que podrían interpretarse como patrones estacionales si tuviéramos más datos. Prophet permite visualizar las componentes de tendencia, estacionalidad y efectos semanales o anuales. En este caso, no se observan componentes significativos por la escasez de datos, pero el modelo está correctamente estructurado para captarlas si se amplía la serie temporal."
      ],
      "metadata": {
        "id": "QpH9GoxVvR_a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "######################PUNTO 3################################\n",
        "#df_copia.head()\n",
        "\n",
        "# Crear la columna de características combinadas\n",
        "dt_df = df.copy()\n",
        "dt_df['features'] = dt_df['Type'] + ' ' + dt_df['State'] + ' ' + dt_df['BestTimeToVisit'] + \" \" + dt_df['Preferences']\n",
        "#dt_df['features'] = destinations_df[['Type', 'State', 'BestTimeToVisit', 'Preferences']].fillna('').agg(' '.join, axis=1)\n",
        "#Vectorizar\n",
        "vectorizer = CountVectorizer(stop_words='english')\n",
        "#Primero creamos la columna 'features' para guardar la inforamación que nos permitirá recomendar el destino al usuario\n",
        "#df_copia['features'] = df_copia['Type'] + ' ' + df_copia['State'] + ' ' + df_copia['BestTimeToVisit'] + \" \" + df_copia['Preferences']\n",
        "\n",
        "dt_df.rename(columns={'DestinationID_x': 'DestinationID','Name_x':'Name'}, inplace=True)\n",
        "feature_matrix = vectorizer.fit_transform(dt_df['features'])\n",
        "destination_features = dt_df\n",
        "\n",
        "cosine_sim = cosine_similarity(feature_matrix, feature_matrix)\n",
        "user_item_matrix = userhistory_df.pivot_table(index='UserID', columns='DestinationID', values='ExperienceRating',aggfunc='mean')\n",
        "\n",
        "user_item_matrix = user_item_matrix.fillna(0)\n",
        "user_similarity = cosine_similarity(user_item_matrix)\n",
        "#print(user_item_matrix,user_similarity)"
      ],
      "metadata": {
        "id": "_W_qH6j2oVYP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def hybrid_recommend(user_id, user_item_matrix, user_similarity, destinations_df,feature_matrix, vectorizer,\n",
        "                     user_preferences=None, top_n=5, k_neighbors=5):\n",
        "    \"\"\"\n",
        "    Recomienda destinos combinando filtrado colaborativo y contenido.\n",
        "\n",
        "    Si el usuario no tiene historial (usuario nuevo), usa sus preferencias.\n",
        "\n",
        "    Args:\n",
        "        user_id (int): ID del usuario.\n",
        "        user_item_matrix (pd.DataFrame): Matriz usuario-destino.\n",
        "        user_similarity (ndarray): Matriz de similitud entre usuarios.\n",
        "        destinations_df (pd.DataFrame): Información de los destinos.\n",
        "        feature_matrix: Matriz de características vectorizadas.\n",
        "        vectorizer: Vectorizador entrenado (CountVectorizer o similar).\n",
        "        user_preferences (dict): Diccionario de preferencias del usuario.\n",
        "        top_n (int): Número de recomendaciones.\n",
        "        k_neighbors (int): Número de vecinos para el filtrado colaborativo.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame con recomendaciones.\n",
        "    \"\"\"\n",
        "\n",
        "    destination_ids = destinations_df['DestinationID'].values\n",
        "\n",
        "    # Caso 1: Usuario conocido (está en la matriz)\n",
        "    if user_id in user_item_matrix.index:\n",
        "        user_idx = user_item_matrix.index.get_loc(user_id)\n",
        "\n",
        "        similarities = user_similarity[user_idx]\n",
        "        # Vecinos más similares (excepto él mismo)\n",
        "        similar_users_idx = np.argsort(similarities)[::-1][1:k_neighbors+1]\n",
        "        similar_users = user_item_matrix.index[similar_users_idx]\n",
        "        # Ratings promedio ponderados por similitud\n",
        "        weighted_ratings = np.zeros(user_item_matrix.shape[1])\n",
        "        similarity_sum = np.zeros(user_item_matrix.shape[1])\n",
        "\n",
        "        for i, neighbor_id in enumerate(similar_users):\n",
        "            sim = similarities[similar_users_idx[i]]\n",
        "            neighbor_ratings = user_item_matrix.loc[neighbor_id].values\n",
        "            weighted_ratings += sim * neighbor_ratings\n",
        "            similarity_sum += (neighbor_ratings > 0) * sim\n",
        "        with np.errstate(divide='ignore', invalid='ignore'):\n",
        "            predicted_ratings = np.true_divide(weighted_ratings, similarity_sum)\n",
        "            predicted_ratings[np.isnan(predicted_ratings)] = 0\n",
        "\n",
        "        user_rated = user_item_matrix.loc[user_id]\n",
        "        unrated_mask = user_rated == 0\n",
        "\n",
        "        unrated_ratings = predicted_ratings[unrated_mask.values]\n",
        "        unrated_destinations = user_item_matrix.columns[unrated_mask]\n",
        "\n",
        "\n",
        "        top_indices = np.argsort(unrated_ratings)[::-1][:top_n]\n",
        "        top_dest_ids = unrated_destinations[top_indices]\n",
        "        top_scores = unrated_ratings[top_indices]\n",
        "\n",
        "\n",
        "        recommendations = destinations_df[destinations_df['DestinationID'].isin(top_dest_ids)].copy()\n",
        "        recommendations['PredictedRating'] = recommendations['DestinationID'].map(dict(zip(top_dest_ids, top_scores)))\n",
        "        recommendations['Reason'] = \"Similar users rated it highly\"\n",
        "\n",
        "    # Caso 2: Usuario nuevo (preferencias como texto)\n",
        "    else:\n",
        "        if user_preferences is None:\n",
        "            raise ValueError(\"User preferences must be provided for new users.\")\n",
        "\n",
        "        # dt_df = df.copy()\n",
        "        # dt_df['features'] = dt_df['Type'] + ' ' + dt_df['State'] + ' ' + dt_df['BestTimeToVisit'] + \" \" + dt_df['Preferences']\n",
        "\n",
        "        pref_str = (\n",
        "            user_preferences.get('Type', '') + ' ' +\n",
        "            user_preferences.get('State', '') + ' ' +\n",
        "            user_preferences.get('BestTimeToVisit', '') + ' ' +\n",
        "            user_preferences.get('Preferences', '')\n",
        "        ).lower()\n",
        "        pref_vector = vectorizer.transform([pref_str])\n",
        "        #print(\"pref_str: \",pref_str,\"\\npref_vector:\", pref_vector)\n",
        "        similarities = cosine_similarity(pref_vector, feature_matrix).flatten()\n",
        "        top_indices = np.argsort(similarities)[::-1][:top_n]\n",
        "\n",
        "        recommendations = destinations_df.iloc[top_indices].copy()\n",
        "        recommendations['PredictedRating'] = similarities[top_indices]\n",
        "        recommendations['Reason'] = \"Matches your preferences\"\n",
        "\n",
        "    # Ordenar y retornar columnas relevantes\n",
        "    recommendations = recommendations.sort_values(by='PredictedRating', ascending=False)\n",
        "    return recommendations[['DestinationID', 'Name', 'Type', 'State', 'BestTimeToVisit', 'Popularity', 'PredictedRating', 'Reason']]\n",
        "#Example: Collaborative recommendations for user 1\n",
        "collaborative_recommendations = hybrid_recommend(\n",
        "    user_id=234,\n",
        "    user_item_matrix=user_item_matrix,\n",
        "    user_similarity=user_similarity,\n",
        "    destinations_df=df_copia,\n",
        "    feature_matrix=feature_matrix,\n",
        "    vectorizer=vectorizer,\n",
        "    top_n=5,\n",
        "    k_neighbors=10\n",
        ")\n",
        "#Display recommendations\n",
        "print(collaborative_recommendations)\n",
        "#New user\n",
        "user_prefs = {'Type': 'Mountain', 'State': 'Antioquia', 'BestTimeToVisit': 'Dry Season', 'Preferences': 'City,Historical'}\n",
        "\n",
        "hybrid_recommend(\n",
        "    user_id=10,  # un ID que no esté en el user_item_matrix\n",
        "    user_item_matrix=user_item_matrix,\n",
        "    user_similarity=user_similarity,\n",
        "    destinations_df=dt_df,\n",
        "    feature_matrix=feature_matrix,\n",
        "    vectorizer=vectorizer,\n",
        "    user_preferences=user_prefs,\n",
        "    top_n=5,\n",
        "    k_neighbors=10\n",
        ")"
      ],
      "metadata": {
        "id": "MC7jlenBcP0s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def recommend_destinations(user_id, userhistory_df, destinations_df, cosine_sim):\n",
        "    \"\"\"\n",
        "    Recommends top 5 destinations for a given user based on similarity scores.\n",
        "\n",
        "    Args:\n",
        "    - user_id: ID of the user.\n",
        "    - userhistory_df: User history DataFrame containing 'UserID' and 'DestinationID'.\n",
        "    - destinations_df: Destinations DataFrame containing destination details.\n",
        "    - cosine_sim: Cosine similarity matrix for destinations.\n",
        "\n",
        "    Returns:\n",
        "    - DataFrame with recommended destinations and their details.\n",
        "    \"\"\"\n",
        "    # Get the destinations the user has visited\n",
        "    visited_destinations = userhistory_df[userhistory_df['UserID'] == user_id]['DestinationID'].values\n",
        "\n",
        "    # Calculate similarity scores for visited destinations\n",
        "    similar_scores = np.sum(cosine_sim[visited_destinations - 1], axis=0)\n",
        "\n",
        "    # Recommend the top 5 destinations the user hasn't visited yet\n",
        "    recommended_destinations_idx = np.argsort(similar_scores)[::-1]\n",
        "\n",
        "    recommendations = []\n",
        "    for idx in recommended_destinations_idx:\n",
        "        if destinations_df.iloc[idx]['DestinationID'] not in visited_destinations:\n",
        "            # Append detailed information for each recommendation\n",
        "            recommendations.append(destinations_df.iloc[idx][[\n",
        "                'DestinationID', 'Name', 'State', 'Type', 'Popularity', 'BestTimeToVisit','ExperienceRating'\n",
        "            ]].to_dict())\n",
        "        if len(recommendations) >= 5:\n",
        "            break\n",
        "\n",
        "    # Convert recommendations to a DataFrame\n",
        "    return pd.DataFrame(recommendations)\n",
        "\n",
        "# Example: Recommend destinations for user with ID 1\n",
        "recommended_destinations = recommend_destinations(100, userhistory_df, df_copia, cosine_sim)\n",
        "\n",
        "# Display recommendations\n",
        "recommended_destinations"
      ],
      "metadata": {
        "id": "rGtqutFi-YUC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def collaborative_recommend(user_id, user_similarity, user_item_matrix, destinations_df, top_n=5,k_neighbors=5):\n",
        "    \"\"\"\n",
        "    Recommends destinations based on collaborative filtering.\n",
        "\n",
        "    Args:\n",
        "    - user_id: ID of the user for whom recommendations are to be made.\n",
        "    - user_similarity: Cosine similarity matrix for users.\n",
        "    - user_item_matrix: User-item interaction matrix (e.g., ratings or preferences).\n",
        "    - destinations_df: DataFrame containing destination details.\n",
        "\n",
        "    Returns:\n",
        "    - DataFrame with recommended destinations and their details.\n",
        "    \"\"\"\n",
        "    #Filter destinations already visited by the user\n",
        "    visited = user_item_matrix.loc[user_id][user_item_matrix.loc[user_id] > 0].index\n",
        "\n",
        "    # Find similar users\n",
        "    similar_users = user_similarity[user_id - 1]\n",
        "\n",
        "    # Get the top 10 most similar users\n",
        "    similar_users_idx = np.argsort(similar_users)[::-1][1:k_neighbors+1]\n",
        "\n",
        "    # Weights by similitude\n",
        "    similar_weights = similar_users[similar_users_idx]\n",
        "    weighted_ratings = user_item_matrix.iloc[similar_users_idx].T.dot(similar_weights) / similar_weights.sum()\n",
        "\n",
        "    # Get the destinations liked by similar users\n",
        "    weighted_ratings = weighted_ratings.drop(labels=visited, errors='ignore')\n",
        "    # Recommend the top 5 destinations\n",
        "    recommended_destinations_ids = weighted_ratings.sort_values(ascending=False).head(top_n).index\n",
        "\n",
        "    # Filter the destinations DataFrame to include detailed information\n",
        "    recommendations = destinations_df[destinations_df['DestinationID'].isin(recommended_destinations_ids)][[\n",
        "        'DestinationID', 'Name', 'State', 'Type', 'Popularity', 'BestTimeToVisit','ExperienceRating'\n",
        "    ]]\n",
        "\n",
        "    return recommendations\n",
        "\n",
        "# Example: Collaborative recommendations for user 1\n",
        "collaborative_recommendations = collaborative_recommend(100, user_similarity, user_item_matrix, destinations_df)\n",
        "\n",
        "# Display recommendations\n",
        "collaborative_recommendations"
      ],
      "metadata": {
        "id": "bOTyBXoCCFbp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def hybrid_recommend(\n",
        "    user_id,\n",
        "    user_item_matrix,\n",
        "    user_similarity,\n",
        "    destinations_df,\n",
        "    feature_matrix,\n",
        "    vectorizer,\n",
        "    user_preferences=None,\n",
        "    top_n=5,\n",
        "    k_neighbors=5\n",
        "):\n",
        "    \"\"\"\n",
        "    Recomienda destinos combinando filtrado colaborativo y contenido.\n",
        "\n",
        "    Si el usuario no tiene historial (usuario nuevo), usa sus preferencias.\n",
        "\n",
        "    Args:\n",
        "        user_id (int): ID del usuario.\n",
        "        user_item_matrix (pd.DataFrame): Matriz usuario-destino.\n",
        "        user_similarity (ndarray): Matriz de similitud entre usuarios.\n",
        "        destinations_df (pd.DataFrame): Información de los destinos.\n",
        "        feature_matrix: Matriz de características vectorizadas.\n",
        "        vectorizer: Vectorizador entrenado (CountVectorizer o similar).\n",
        "        user_preferences (dict): Diccionario de preferencias del usuario.\n",
        "        top_n (int): Número de recomendaciones.\n",
        "        k_neighbors (int): Número de vecinos para el filtrado colaborativo.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame con recomendaciones.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Intentar acceder al usuario en la matriz\n",
        "        if user_id in user_item_matrix.index:\n",
        "            # --- Filtrado colaborativo ---\n",
        "            #Filter destinations already visited by the user\n",
        "          visited = user_item_matrix.loc[user_id][user_item_matrix.loc[user_id] > 0].index\n",
        "\n",
        "          # Find similar users\n",
        "          similar_users = user_similarity[user_id - 1]\n",
        "\n",
        "          # Get the top 10 most similar users\n",
        "          similar_users_idx = np.argsort(similar_users)[::-1][1:k_neighbors+1]\n",
        "\n",
        "          # Weights by similitude\n",
        "          similar_weights = similar_users[similar_users_idx]\n",
        "          weighted_ratings = user_item_matrix.iloc[similar_users_idx].T.dot(similar_weights) / similar_weights.sum()\n",
        "\n",
        "          # Get the destinations liked by similar users\n",
        "          weighted_ratings = weighted_ratings.drop(labels=visited, errors='ignore')\n",
        "          # Recommend the top 5 destinations\n",
        "          recommended_destinations_ids = weighted_ratings.sort_values(ascending=False).head(top_n).index\n",
        "\n",
        "          # Filter the destinations DataFrame to include detailed information\n",
        "          recommendations = destinations_df[destinations_df['DestinationID'].isin(recommended_destinations_ids)][[\n",
        "              'DestinationID', 'Name', 'State', 'Type', 'Popularity', 'BestTimeToVisit', 'ExperienceRating'\n",
        "          ]]\n",
        "\n",
        "          return recommendations\n",
        "\n",
        "        else:\n",
        "            raise KeyError  # Forzar salto al except si no está en el índice\n",
        "\n",
        "    except KeyError:\n",
        "        # --- Usuario nuevo: recomendación basada en contenido ---\n",
        "        if user_preferences is None:\n",
        "            raise ValueError(\"Usuario nuevo: se requieren preferencias para recomendación basada en contenido.\")\n",
        "\n",
        "        preference_str = (\n",
        "            user_preferences.get('Type', '') + ' ' +\n",
        "            user_preferences.get('State', '') + ' ' +\n",
        "            user_preferences.get('BestTimeToVisit', '')\n",
        "        )\n",
        "        preference_vector = vectorizer.transform([preference_str])\n",
        "        similarity_scores = cosine_similarity(preference_vector, destination_features).flatten()\n",
        "        top_indices = similarity_scores.argsort()[::-1][:top_n]\n",
        "\n",
        "        return destinations_df.iloc[top_indices][[\n",
        "            'DestinationID', 'Name', 'Type', 'State', 'BestTimeToVisit', 'Popularity','ExperienceRating'\n",
        "        ]]\n",
        "# Example: Collaborative recommendations for user 1\n",
        "collaborative_recommendations = hybrid_recommend(\n",
        "    user_id=5,\n",
        "    user_item_matrix=user_item_matrix,\n",
        "    user_similarity=user_similarity,\n",
        "    destinations_df= df_copia, #destinations_df,\n",
        "    feature_matrix=feature_matrix,\n",
        "    vectorizer=vectorizer,\n",
        "    top_n=5,\n",
        "    k_neighbors=10\n",
        ")\n",
        "# Display recommendations\n",
        "print(collaborative_recommendations)\n",
        "#New user\n",
        "user_prefs = {'Type': 'Mountain', 'State': 'Antioquia', 'BestTimeToVisit': 'Dry Season'}\n",
        "\n",
        "hybrid_recommend(\n",
        "    user_id=10,  # un ID que no esté en el user_item_matrix\n",
        "    user_item_matrix=user_item_matrix,\n",
        "    user_similarity=user_similarity,\n",
        "    destinations_df=df_copia,\n",
        "    feature_matrix=feature_matrix,\n",
        "    vectorizer=vectorizer,\n",
        "    user_preferences=user_prefs,\n",
        "    top_n=5,\n",
        "    k_neighbors=10\n",
        ")"
      ],
      "metadata": {
        "id": "jADKL7dhP5ga"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}